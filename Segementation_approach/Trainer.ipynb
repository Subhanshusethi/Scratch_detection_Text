{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNET(\n",
      "  (ups): ModuleList(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (3): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (5): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (7): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (downs): ModuleList(\n",
      "    (0): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (bottleneck): DoubleConv(\n",
      "    (relusig): ReluSIG(\n",
      "      (gelu): GELU(approximate='none')\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (add_skip): ListSkip(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (conv3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (conv1d): Conv2d(64, 256, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n",
      "    (conv1dd): Conv2d(64, 512, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1))\n",
      "    (conv2d): Conv2d(128, 512, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%run model.ipynb\n",
    "%run utils.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 40\n",
    "NUM_WORKERS = 0\n",
    "IMAGE_HEIGHT = 160\n",
    "IMAGE_WIDTH = 240\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "TRAIN_IMG_DIR= \"im\"\n",
    "TRAIN_MASK_DIR = \"ma\"\n",
    "VAL_MASK_DIR = \"ma\"\n",
    "VAL_IMG_DIR =\"im\"\n",
    "hyp1 = \"C:/Users/haZAR/Desktop/Subahnshu_Sethi_ResearchTeam/Segmentation/Model_weights/Hypothises1CONCATskipAND ATTENTION.pth.tar\"\n",
    "hyp2 = \"C:/Users/haZAR/Desktop/Subahnshu_Sethi_ResearchTeam/Segmentation/Model_weights/Hypothisesconcatskip_att_gelusig.pth.tar\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Learning rate scheduler with warmup utility.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class LRWarmup:\n",
    "    \"\"\"\n",
    "    Self-made learning rate scheduler with warmup.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs, max_lr, k):\n",
    "        assert k < 0.95 and k > 0.05, \"k must be between 0.05 and 0.95\" \n",
    "        self.epochs = epochs\n",
    "        self.max_lr = max_lr\n",
    "        self.max_point = int(k * self.epochs)\n",
    "        #go to top and come down\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        return self.lr_warmup(epoch)\n",
    "\n",
    "    def lr_warmup(self, epoch):\n",
    "        a_1 = self.max_lr / self.max_point\n",
    "        a_2 = self.max_lr / (self.max_point - self.epochs)\n",
    "\n",
    "        b = -a_2 * self.epochs\n",
    "                                            \n",
    "                                            #llok at this \n",
    "        return min(a_1 * epoch, a_2 * epoch + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn):\n",
    "\n",
    "    loop = tqdm.tqdm(loader)\n",
    "    losses = []\n",
    "\n",
    "    for (data,targets) in (loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        # print(\"ollllllllllllAA\",data.shape)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "        # print(targets.shape)\n",
    "        predictions = model(data)\n",
    "\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return sum(losses) / len(losses)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60\n",
      "Number of validation samples: 60\n",
      "Got 2175754/2304000 with acc 94.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.89it/s, loss=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2081402/2304000 with acc 90.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.27it/s, loss=0.803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2046504/2304000 with acc 88.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.43it/s, loss=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2046037/2304000 with acc 88.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.33it/s, loss=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2034576/2304000 with acc 88.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.21it/s, loss=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2042000/2304000 with acc 88.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.23it/s, loss=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2052862/2304000 with acc 89.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.26it/s, loss=0.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2048254/2304000 with acc 88.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.24it/s, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2057414/2304000 with acc 89.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.24it/s, loss=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2037870/2304000 with acc 88.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.33it/s, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2061892/2304000 with acc 89.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.24it/s, loss=0.921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2047525/2304000 with acc 88.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.25it/s, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2070457/2304000 with acc 89.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.26it/s, loss=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2057938/2304000 with acc 89.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.28it/s, loss=0.926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2057088/2304000 with acc 89.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.27it/s, loss=0.857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2054671/2304000 with acc 89.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.27it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2079848/2304000 with acc 90.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.25it/s, loss=0.797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2060041/2304000 with acc 89.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.20it/s, loss=0.942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2076113/2304000 with acc 90.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.12it/s, loss=0.809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2063728/2304000 with acc 89.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.09it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2090571/2304000 with acc 90.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.22it/s, loss=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2093763/2304000 with acc 90.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.05it/s, loss=0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2103341/2304000 with acc 91.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:06<00:00,  9.52it/s, loss=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2100500/2304000 with acc 91.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.17it/s, loss=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2097280/2304000 with acc 91.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.15it/s, loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2106422/2304000 with acc 91.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.25it/s, loss=0.819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2102197/2304000 with acc 91.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.24it/s, loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2117926/2304000 with acc 91.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.21it/s, loss=0.731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2118598/2304000 with acc 91.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.19it/s, loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2120926/2304000 with acc 92.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.19it/s, loss=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2123217/2304000 with acc 92.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.20it/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2127507/2304000 with acc 92.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.21it/s, loss=0.69] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2131801/2304000 with acc 92.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.21it/s, loss=0.72] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2129565/2304000 with acc 92.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.23it/s, loss=0.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2133584/2304000 with acc 92.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.22it/s, loss=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2135894/2304000 with acc 92.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.19it/s, loss=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2134690/2304000 with acc 92.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.22it/s, loss=0.653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2136169/2304000 with acc 92.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.22it/s, loss=0.755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2143138/2304000 with acc 93.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.22it/s, loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2134505/2304000 with acc 92.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:05<00:00, 10.23it/s, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Got 2138144/2304000 with acc 92.80\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX+0lEQVR4nO3deVhUZf8G8PvMwAw7yC6CgBu4sCgKoqamvK6RW+WWW6Wvpi3SJuZS9hYt78+sNC3DdtPcynJJxS0VRUFEFMEtQGBYVHbZZs7vD3R6J0HZDzD357rmUs6cc+b7dKq5eZ7nnEcQRVEEERERkR6RSV0AERERUVNjACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3DKQuoDnSaDRIT0+Hubk5BEGQuhwiIiKqAVEUUVBQACcnJ8hkD+7jYQCqQnp6OlxcXKQug4iIiOogNTUVzs7OD9yHAagK5ubmACr/AVpYWEhcDREREdVEfn4+XFxctN/jD8IAVIV7w14WFhYMQERERC1MTaavcBI0ERER6R0GICIiItI7DEBERESkdxiAiIiISO8wABEREZHeYQAiIiIivcMARERERHqHAYiIiIj0DgMQERER6R0GICIiItI7DEBERESkdxiAiIiISO9IHoDWrFkDNzc3GBkZISAgAFFRUQ/cf9WqVfDw8ICxsTFcXFywcOFClJSU6OyTlpaGp59+GjY2NjA2NoaXlxfOnDnTmM1o9UrK1Sir0EhdBhERUYOQdDX4zZs3IyQkBOvWrUNAQABWrVqF4cOHIzExEfb29vftv3HjRixatAgbNmxAv379kJSUhJkzZ0IQBKxcuRIAcPv2bfTv3x+PPvoo9uzZAzs7O1y+fBlt2rRp6ua1CqIoYltMGlb8dgGGchleCuqMyf7tYSiXPDsTERHVmSCKoijVhwcEBKBPnz5YvXo1AECj0cDFxQUvvPACFi1adN/+CxYsQEJCAiIiIrTbXnnlFZw6dQrHjh0DACxatAjHjx/Hn3/+Wee68vPzYWlpiby8PFhYWNT5PC2dKq8EodvjcCgxW2e7u60p3hjhgeHdHSEIgkTVERER6arN97dkv8aXlZUhOjoaQUFBfxcjkyEoKAiRkZFVHtOvXz9ER0drh8muXbuG3bt3Y9SoUdp9du7cid69e+PJJ5+Evb09evbsifXr1z+wltLSUuTn5+u89Jkoivj5TCr+9fERHErMhkIuw+sjPPDO2B6wNVPgek4R5v4QgwlrT+DMX7ekLpeIiKjWJBsCy8nJgVqthoODg852BwcHXLp0qcpjpkyZgpycHAwYMACiKKKiogJz587F4sWLtftcu3YNa9euRUhICBYvXozTp0/jxRdfhEKhwIwZM6o8b1hYGN5+++2Ga1wLlp57B4u2n8fRpMpeH18XK3z0hDc6O5gDAMb1bIcvj1zF+j+vIyYlF0+si8Tw7g54fYQnOtqZSVk6ERFRjbWoiRyHDx/Ge++9h88//xwxMTHYvn07du3ahXfeeUe7j0ajQa9evfDee++hZ8+emDNnDmbPno1169ZVe97Q0FDk5eVpX6mpqU3RnGZFFEVsikrBsI+P4mhSNhQGMiwe5Ylt8/ppww8AmCkNEDLMA4dfG4zJ/i6QCcAfFzIx7OOjWPLLeWQXlErYCiIiopqRrAfI1tYWcrkcmZmZOtszMzPh6OhY5TFLly7FtGnT8NxzzwEAvLy8UFRUhDlz5uDNN9+ETCZD27Zt0a1bN53junbtim3btlVbi1KphFKprGeLWq603DtYtC0Of17OAQD0am+FD5/wQSf76nt0HCyMEDbeG8/0d8cHey/hQEIWfjiZgh0xaZgzsCNmD3SHiULSOfZERETVkqwHSKFQwM/PT2dCs0ajQUREBAIDA6s8pri4GDKZbslyuRxAZQ8GAPTv3x+JiYk6+yQlJcHV1bUhy2905WoNYlJu4/iVHDTWPHVRFLHxVAqGf3wUf17OgdJAhiWju2LL3H4PDD//q7ODOb6a0Qeb5vSFj7MlisrU+PhAEgZ9dBhxN3IbpW4iIqL6kvRX9JCQEMyYMQO9e/eGv78/Vq1ahaKiIsyaNQsAMH36dLRr1w5hYWEAgODgYKxcuRI9e/ZEQEAArly5gqVLlyI4OFgbhBYuXIh+/frhvffew1NPPYWoqCh8+eWX+PLLLyVrZ02UVWgQdyMXp67fwslrNxGdfBvFZWoAwLvjemBqQMMGOFVeCV7dcg7HrlT2+vi5tsFHT3ijQx3n8fTtYINf5vfHrvMZ+HBvIlJuFeOtnRewbV4/3ilGRETNjqQBaOLEicjOzsayZcugUqng6+uLvXv3aidGp6Sk6PT4LFmyBIIgYMmSJUhLS4OdnR2Cg4Px7rvvavfp06cPduzYgdDQUKxYsQLu7u5YtWoVpk6d2uTte5DSCjViUyoDz6nrlYGnpFz3QYMmCjmKy9R4d1cCHulkh/Y2Jg322c98cxoXM/JhZCjDa8M9MbOfG+Sy+gUVQRDwmLcT/N2tMeD9Q4hJycXpv27D3926QeomIiJqKJI+B6i5aqznACVlFmBXXAZOXb+JmJTc+56sbG2qQIC7NQLcrdG3ow062Zlh6lencOr6Lfi7WWPTnL6Q1TOkAMB/fr+Ir45dh7WpAlvnBta51+dBQrfH4aeoVAzxtMeGmX0a/PxERET/VJvvb85SbUKxKbn4JOKy9mdbMyUCOlijr7s1+nawQSd7s/uGi/77pA+GrzqKqL9uYcPx63jukQ71quFIUja+OnYdAPDhhLoPeT3M7Ec6YNPpVBy8lIVEVQE8HM0ffhAREVETYQBqQoEdbfC4jxMCOlgjwN0GHe1MHzo/xsXaBEtGd8PiHefx4R+JGOxhh072dQsTOYWleOXncwCAGYGuCOrm8JAj6q6DnRlGdHfEnngVvjhyFSsn+jbaZxEREdVWi3oOUEvnYm2CTyf3xNQA1yp7e6oz2d8FA7vYoaxCg1d+PocKde0XJRVFEa9uOYecwlJ4OJgjdFTXWp+jtuYO6ggA2HkuHWm5dxr984iIiGqKAagFEAQBH07whoWRAc7dyMPaw1drfY5vTvyFw4mVDzj8dHJPGBnKG6FSXT4uVgjsYIMKjYiv/rzW6J9HRERUUwxALYSjpRFWjOkBAPgk4jIupOfV+NiEjHyE7a5cXmTJ6K5NOh9n7uDKXqBNUam4XVTWZJ9LRET0IAxALcgYXyeM6O6ICo2IV34+h9IK9UOPuVOmxgs/nUWZWoOgrvaY1rdpHwg5sLMturW1wJ1yNb4/mdykn01ERFQdBqAWRBAE/GdcD9iYKnBJVYBPDlx+6DH/2XURV7IKYW+uxIdP+DT5QwkFQcC/B1XeufbNib9wp+zhoY2IiKixMQC1MLZmSrw7zgsAsO7IVcSk3K523z8uqPDjqRQAwMqnfGFtqmiSGv9ptFdbuFgb41ZRGbZE12+h2VtFZfhg7yX8HpeO8jpMBiciIgIYgFqkET0cMb5nO2hE4NWfz1XZq5KRdwdvbIsDAPx7YAcM6Gzb1GVqGchlmH33+UVfHr1Wp7vYAKCkXI3Z353B2sNXsWDjWfR//yA+OXAZWQUlDVkuERHpAQagFmp5cHc4WhjhWk4RPth7Sec9tUZEyOZzyC0uR492FnhlmIdEVf7tST8XWJsqcOP2Hew6n1Hr40VRxKJtcYhOvg1zIwPYmSuRVVCKjw8kof/7B/HiT2cRnXyr0RaOJSKi1oUBqIWyNDHEB094A6icW3Piao72vS+OXkXktZswNpTj00k9oTCQ/jIbK+SY2c8NALDuyLVaB5XVB6/gl9h0yGUC1j3th+NvDMEnk3zh59oG5WoRO8+lY8LaSASvPoafz6SipJxzjYiIqHrSfzNSnQ3qYocpAe0BAK9tiUNBSTliU3Oxcl8SAODtx7s32lIXdTE90BUmCjkSMvJx9HLOww+46/e4dPzf/so2vTOmB/p3soXCQIYxvu2wbV4//P7CADzV2xlKAxni0/Lx+tY49A2LQNieBKTeKm6s5hARUQvGxVCr0FiLoTaGwtIKjPzkKFJv3cFYXyecTc1F8s1ijPZui9WTezb5XV8Ps+K3i9hw/DoCO9jgpzl9H7p/bGouJn4RidIKDZ4d4I6lj3Wrdt/bRWXYfCYV30cma588LQjAI53t0Me1DbycLeHtbCXZZHAiImpctfn+ZgCqQksKQABw6tpNTFp/EveuZDsrY+x+8RFYmhhKW1gV0nPvYOCHh1ChEfHr/P7wcbGqdt+03DsYs/o4cgpLMcTTHuun94Zc9vBAp9aIOHgpC9+e+AvHrtzf0+RibQzvdlbwdraEl7MlvNpZwtyo+f2zIiKi2mEAqqeWFoAA4D+/X8RXx65DJgCb5gTC391a6pKqFfJzLLbHpGFkD0esfdqvyn0KSyvwxNoTuKQqgKejObbO6wczZe3X7r2SVYgjSdmIu5GL8zfycC2n6L59BAHoYGsKb+fKUDTaqy3sLYxq/VlERCQtBqB6aokBqKRcjQ/2XkIPJ0tM8HOWupwHSsoswLCPj0IQgIiQQffNU1JrRPz7+zM4kJAFWzMlfpnfD85tTBrks/PulONCWh7O3cjD+bRcnEvNu2+h1h7tLPDbggHNbviQiIgerDbf37X/lZqaJSNDOZYHd5e6jBrp4mCOoZ72iLiUhfV/XkPYeG+d99/fk4ADCVlQGMiwfrpfg4UfALA0NkS/Trbo1+nv5yLlFJbifFoe4lLzsPbIFcSn5ePktVsI7GjTYJ9LRETNC+8CI0ncWyR1W3QasvL/fpDhT1EpWP/ndQDA/z3pg57t2zR6LbZmSjzqYY+XgjpjQq/K3rPwY9cb/XOJiEg6DEAkiT5u1vBzbYMytQYbjv8FADh+JQdLf4kHACwM6oJgH6cmr2tWf3cAQMSlTPxVxXwhIiJqHRiASDJzB1X2Av14MhnnUnMx74doVGhEPO7jhBeHdpKkpk72ZhjsYQdRrHzAJBERtU4MQCSZoZ726GxvhoLSCjy5LhL5JRXo1d4KHz7hLekE5GcHVPYC/XwmFXl3yiWrg4iIGg8DEElGJhMwZ2DlIqllag3aWRnji2m9YWQol7SuAZ1s0cXBDMVlavx8un6r1xMRUfPEAESSGuPbDh3tTGFpbIgNM/vAzlwpdUkQBAHP3J0L9M2Jv+q8ej0RETVfDEAkKYWBDL+/8AiOvfEoPBzNpS5Ha2zPdrA2VSAt9w7+uJApdTlERNTAGIBIcsYKebNbisLIUI6n7y40u+E4b4knImptGICIqvF0X1cYygVEJ99GbGqu1OUQEVEDYgAiqoa9hZH2WUQb+GBEIqJWhQGI6AHuTYbefT4DGXl3HrI3ERG1FAxARA/Qo50lAtytUaER8e2JZKnLISKiBsIARPQQ9x6M+FNUCorLKiSuhoiIGgIDENFDDO3qAFcbE+TdKce2mDSpyyEiogbAAET0EHKZgJn93AAAXx+7Do1GlLYgIiKqNwYgohp4srcLzJUGuJZThCNJ2VKXQ0RE9cQARFQDZkoDTPJ3AQCE85Z4IqIWjwGIqIamB7pBJgDHruTgkiq/VseWlKvx85lUfHP8Ov68nI303DsQRQ6lERFJpVkEoDVr1sDNzQ1GRkYICAhAVFTUA/dftWoVPDw8YGxsDBcXFyxcuBAlJSVV7vv+++9DEAS8/PLLjVA56RMXaxOM6OEIAPj62F81OkYURew8l46glUfw+tY4vPXbRUwLj0K/9w+i+/I/8Nhnf+KlTWfxacRl7IrLwCVVPkrK1Y3YCiIiAgADqQvYvHkzQkJCsG7dOgQEBGDVqlUYPnw4EhMTYW9vf9/+GzduxKJFi7Bhwwb069cPSUlJmDlzJgRBwMqVK3X2PX36NL744gt4e3s3VXOolXt2gDt2n1dhR2waXhvhAVuz6levP/3XLfxnVwLO3V1Gw8FCCW9nK1zLLkTyzWIUl6kRn5aP+DTd3iRBAFzamKBbWwu8PsIDHezMGrNJRER6SfIAtHLlSsyePRuzZs0CAKxbtw67du3Chg0bsGjRovv2P3HiBPr3748pU6YAANzc3DB58mScOnVKZ7/CwkJMnToV69evx3/+858H1lBaWorS0lLtz/n5tRveIP3Rq30b+Dhb4tyNPPx4MgUvBXW+b5/rOUX4YM8l7L2gAgCYKOSYO6gjnnvEHSaKyv/kytUapNwqxtWsQlzNLsLV7EJczS7ElaxCFJRUIOVWMVJuFSPuRi62P98fjpZGTdpOIqLWTtIhsLKyMkRHRyMoKEi7TSaTISgoCJGRkVUe069fP0RHR2uHya5du4bdu3dj1KhROvvNnz8fo0eP1jl3dcLCwmBpaal9ubi41KNV1JoJgoBn7j4Y8fuTySit+Hu46nZRGd7+7QL+tfII9l5QQSYAk/3b4/Brg/Hi0M7a8AMAhnIZOtqZYVh3R8wb3BH/fdIHO57vj7jlw3D6zSBsnB2ADnamSM8rwYwNUci7U97kbSUias0kDUA5OTlQq9VwcHDQ2e7g4ACVSlXlMVOmTMGKFSswYMAAGBoaomPHjhg8eDAWL16s3WfTpk2IiYlBWFhYjeoIDQ1FXl6e9pWamlr3RlGrN8qrLRwtjJBTWIrfzmWgtEKNL49excCPDuHr43+hQiNisIcd9rw0EGHjvWBvXvPeG0EQYGeuRL+Otvh2lj/szZVIzCzA7O/OcG4QEVEDahaToGvj8OHDeO+99/D5558jJiYG27dvx65du/DOO+8AAFJTU/HSSy/hxx9/hJFRzb54lEolLCwsdF5E1TGUyzC9nysA4NOIyxj6f0fw3u5LKCipgKejOb5/1h/fzPKHh6N5vT7HxdoE3z7jD3OlAaKu38LLm2Kh5kMYiYgahCBKeC9uWVkZTExMsHXrVowdO1a7fcaMGcjNzcWvv/563zGPPPII+vbti48++ki77YcffsCcOXNQWFiInTt3Yty4cZDL5dr31Wo1BEGATCZDaWmpzntVyc/Ph6WlJfLy8hiGqEq5xWUIDDuIO3d7ZRwslHh1mAfG93KGXCY06GdFXr2JGRuiUKbWYFpfV6wY0x2C0LCfQUTUGtTm+1vSHiCFQgE/Pz9ERERot2k0GkRERCAwMLDKY4qLiyGT6ZZ9L9CIooihQ4fi/PnziI2N1b569+6NqVOnIjY29qHhh6gmrEwUeCmoMxwtjBDyry449OpgPNnbpcHDDwAEdrTBxxN9IQiV845WH7xSr/OpNSLi0/LYm0REek3yu8BCQkIwY8YM9O7dG/7+/li1ahWKioq0d4VNnz4d7dq1087nCQ4OxsqVK9GzZ08EBATgypUrWLp0KYKDgyGXy2Fubo4ePXrofIapqSlsbGzu205UH3MHdcTcQR2b5LNGe7dFTmF3LN95Af+3Pwl25kpM8m9fq3OIoogjSdkI230JiZkFCPZxwqeTfNmbRER6SfIANHHiRGRnZ2PZsmVQqVTw9fXF3r17tROjU1JSdHp8lixZAkEQsGTJEqSlpcHOzg7BwcF49913pWoCUZOY0c8NWQUlWHPoKhbvOA9bMyWCujk8/EAAF9PzEbYnAX9eztFu++1cOvp1tMHkWgYpIqLWQNI5QM0V5wBRcyWKIl7fGoct0TegNJBh4+wA+LlaV7u/Kq8E/7cvEVtjbkAUAYVchhn9XGGsMMCnEZehNJDhtxcGoItD/SZsExE1B7X5/pa8B4iIak4QBISN98LNojIcvJSFZ789g61zA9HJXjfAFJZW4MsjV/Hln9dQUq4BADzm3RavD/dEexsTaDQiYlNzcTQpGws2xuDX+QNgrOD8OCLSHy3uNngifWcgl2H1lJ7wdbFCbnE5podHQZVXuRZehVqDjadSMPijw/j04BWUlGvQ27UNtj/fD6un9EJ7GxMAgEwmYOVTPrAzVyIpsxArfr8oZZOIiJoch8CqwCEwagluFZXhiXUncC27CB4O5ngpqDM+3p+Ey1mFAAA3GxMsGumJ4d0dq53ofOxyDqZtOAVRBFZP6YnHvJ2asglERA2qNt/fDEBVYACiliL1VjEmrD2BrIK/17KzMjHEi0M64+m+rlAYPLyT96M/LmHNoaswVxpg90uPwMXapDFLJiJqNC3mOUBEVD/3nhZtYWQAhVyGOQM74Mirj+KZAe41Cj8A8HJQF/i5tkFBaQUW/HQW5WpNI1dNRCQ99gBVgT1A1NLcKiqDKIqwMVPW6fgbt4sx6pM/kV9SgX8P6oDQkV0buEIiosbHHiAiPWNtqqhz+AEA5zYm+PAJbwDAF0eu4UhSdkOVRkTULDEAEREAYESPtpjWt3KR15DNscjKL5G4IiKixsMARERab47uCk9Hc9wsKsPCn2Oh4XphRNRKMQARkZaRoRyrp/SEsaEcx6/cxNojV6UuiYioUTAAEZGOTvbmeHtMdwDAyv1JiE6+JXFFREQNjwGIiO7zpJ8zxvg6Qa0R8eJPscgrLpe6JCKiBsUARET3EQQB/xnbA642JkjLvYPXt50Dn5hBRK0JAxARVcncyBCfTe4JQ7mAPy5k4tOIK1KXRETUYBiAiKha3s5WWDGmBwDg4wNJ2HH2hsQVERE1DAYgInqgyf7t8e9BHQAAr2+Nw8lrNyWuiIio/hiAiOih3hjuiVFejihXi/j399G4ml0odUlERPXCAEREDyWTCVj5lC96trdC3p1yzPr6NG4Wlj78QCKiZooBiIhqxMhQjvXTe8PF2hgpt4ox+7szKClXS10WEVGdMAARUY3Zminx9Ux/WBobIiYlF6/8fI7LZRBRi8QARES10sneDF9M84OhXMCu8xn48I9EqUsiIqo1BiAiqrW+HWzwwQRvAMC6I1fxU1SKxBUREdUOAxAR1cn4Xs54aWhnAMCSX+JxNClb4oqIiGqOAYiI6uzloM4Y37Md1BoRz/8Yg0uqfKlLIiKqEQYgIqozQRAQNsELAe7WKCytwDNfn0ZmfonUZRERPRQDEBHVi9JAji+n9UYHO1Ok55Xg2W9Po6i0QuqyiIgeiAGIiOrN0sQQ38z0h42pAvFp+Zi8/iQSVQVSl0VEVC0GICJqEO1tTLB+Rm+YGxkg7kYeHvvsT3wacRnlao3UpRER3YcBiIgaTK/2bbB/4SAEdbVHuVrEyv1JeHz1ccSn5UldGhGRDgYgImpQjpZGWD+9Nz6Z5Is2JoZIyMjHmDXH8d8/ElFawaUziKh5YAAiogYnCALG+LbD/pBBGO3VFmqNiNWHrmD0p8dwNuW21OURETEAEVHjsTVTYs3UXlg7tRdszZS4klWICWtP4N1dF3GnjL1BRCQdBiAianQjvdpi/8KBGN+zHTQisP7P6xj5yVGcunZT6tKISE8xABFRk2hjqsDKib7YMLM3HC2M8NfNYkz88iSW/RqPsgreKUZETatZBKA1a9bAzc0NRkZGCAgIQFRU1AP3X7VqFTw8PGBsbAwXFxcsXLgQJSV/P302LCwMffr0gbm5Oezt7TF27FgkJnLFaqLmYIinA/aFDMRkfxcAwHeRyVi4ORZqjShxZUSkTyQPQJs3b0ZISAiWL1+OmJgY+Pj4YPjw4cjKyqpy/40bN2LRokVYvnw5EhISEB4ejs2bN2Px4sXafY4cOYL58+fj5MmT2L9/P8rLyzFs2DAUFRU1VbOI6AEsjAwRNt4bX03vDUO5gF3nM7B4+3mIIkMQETUNQZT4/zgBAQHo06cPVq9eDQDQaDRwcXHBCy+8gEWLFt23/4IFC5CQkICIiAjttldeeQWnTp3CsWPHqvyM7Oxs2Nvb48iRIxg4cOBDa8rPz4elpSXy8vJgYWFRx5YRUU3sOZ+B+RtjoBGB5wa4483RXSEIgtRlEVELVJvvb0l7gMrKyhAdHY2goCDtNplMhqCgIERGRlZ5TL9+/RAdHa0dJrt27Rp2796NUaNGVfs5eXmVD2Gztrau8v3S0lLk5+frvIioaYz0aosPJngDAL46dh2fHbwicUVEpA8MpPzwnJwcqNVqODg46Gx3cHDApUuXqjxmypQpyMnJwYABAyCKIioqKjB37lydIbD/pdFo8PLLL6N///7o0aNHlfuEhYXh7bffrl9jiKjOnuztgoKSCqz4/SJW7k+CuZEBZvV3l7osImrFJJ8DVFuHDx/Ge++9h88//xwxMTHYvn07du3ahXfeeafK/efPn4/4+Hhs2rSp2nOGhoYiLy9P+0pNTW2s8omoGs8McMfCoC4AgLd/u4it0TckroiIWjNJe4BsbW0hl8uRmZmpsz0zMxOOjo5VHrN06VJMmzYNzz33HADAy8sLRUVFmDNnDt58803IZH9nugULFuD333/H0aNH4ezsXG0dSqUSSqWyAVpERPXx4tBOyC8pR/ix63h96zmYKeUY0aOt1GURUSskaQ+QQqGAn5+fzoRmjUaDiIgIBAYGVnlMcXGxTsgBALlcDgDaO0hEUcSCBQuwY8cOHDx4EO7u7EonagkEQcCS0V3xVG9naETgxZ9i8eflbKnLIqJWSPIhsJCQEKxfvx7ffvstEhISMG/ePBQVFWHWrFkAgOnTpyM0NFS7f3BwMNauXYtNmzbh+vXr2L9/P5YuXYrg4GBtEJo/fz5++OEHbNy4Eebm5lCpVFCpVLhz544kbSSimhMEAWHjvTHKyxFlag3mfBeN6GSuH0ZEDUvSITAAmDhxIrKzs7Fs2TKoVCr4+vpi79692onRKSkpOj0+S5YsqfwtcckSpKWlwc7ODsHBwXj33Xe1+6xduxYAMHjwYJ3P+vrrrzFz5sxGbxMR1Y9cJuDjib4oLI3G0aRszPo6CpvmBKKb04Nva61Qa3BJVYCzKbcRnXwbt4rLETbeC+2sjJuociJqKSR/DlBzxOcAETUPxWUVmB4ehTPJt2FrpsCWuf3gbmuqff92URnOpt5GTHIuopNv49yNXBT/Y5HVZwe4Y+lj3Zq6dCKSQG2+vxmAqsAARNR85N0px+QvT+JiRj7aWRlj7qAOOHcjDzEpt3Et+/6nu5srDeDb3gq2ZkrsOJsGJ0sjHF80hA9XJNIDtfn+lnwIjIjoQSyNDfHds/54al0kruUUYemvF3Te72Bril6ubdCrfRv4ubZBJ3szyGUCSsrV2HdBhfS8EsSm5qJn+zYStYCImiMGICJq9mzNlPjhuQC8vDkWMgHwc60MOz1d2qCNqaLKY4wM5RjS1QG/nUvHnngVAxAR6WAAIqIWwcnKGD//u+rHY1RntJcjfjuXjt3nMxA60pPDYESkJflt8EREjWVQF3sYG8px4/YdnE/Lk7ocImpGGICIqNUyVsgxpKs9AGD3eZXE1RBRc8IARESt2qi7S2nsPp8B3vRKRPcwABFRq/aopx2MDGVIuVWMC+n5UpdDRM0EAxARtWomCgM86nFvGCxD4mqIqLlgACKiVm+UF4fBiEgXAxARtXpDPO2hNJDhr5vFSMgokLocImoGGICIqNUzVRpgsIcdAGBPPIfBiIgBiIj0xL1hsF0cBiMiMAARkZ4Y4mkPhYEM17KLkJRZKHU5RCQxBiAi0gvmRoYY2LlyGGwX7wYj0nsMQESkN0Z5OQIA9jAAEek9BiAi0htB3RxgKBdwOasQlzN5NxiRPmMAIiK9YWFkiEfuDoNxbTAi/cYARER65X8fikhE+osBiIj0yr+6Vg6DJWYW4EoW7wYj0lcMQESkVyxNDNG/ky0AToYm0mcMQESkd0b1uDsMFs95QET6igGIiPTOsO4OMJAJSMjIx/WcIqnLISIJMAARkd6xMlEgsKMNAE6GJtJXDEBEpJfu3Q3GxVGJ9BMDEBHppeHdHSGXCYhPy0fKzeJaHXvy2k0s+eU8btyu3XFE1HwwABGRXrI2VaBvB2sAwO4a9gKVlKvxzu8XMenLk/jhZApW/HaxMUskokbEAEREeqs2D0WMu5GLxz47hvBj17XbIi5lISPvTqPVR0SNhwGIiPTW8O6OkAlA3I08pN6qejirXK3BqgNJGPf5CVzJKoSduRIbZvaGv7s11BoRm0+nNnHVRNQQGICISG/ZmikR4F55N1hVk6GvZBViwtoTWHXgMtQaEaO92mLfywMxxNMBT/d1BQBsikpFhVrTpHUTUf0xABGRXhvl5QhAd3FUjUbEhmPXMfrTPxF3Iw8WRgb4ZJIvVk/piTamCgDA8O4OsDFVQJVfgohLWZLUTkR1xwBERHpteA9HCAIQm5qLtNw7uHG7GFO/OoUVv19EaYUGA7vYYd/CQRjj2w6CIGiPUxrI8WRvFwDAj6dSpCqfiOqIAYiI9Jq9uRH6uFXeDbbsl3iMWPUnIq/dhLGhHP8Z2wPfzuoDR0ujKo+d4t8eggAcTcqu9a30RCQtBiAi0nuj794NFnEpC4WlFejV3gp7XnoET/d11en1+af2NiYY2NkOALAxir1ARC1JswhAa9asgZubG4yMjBAQEICoqKgH7r9q1Sp4eHjA2NgYLi4uWLhwIUpKSup1TiLSXyN7OMJMaQBDuYDXR3hgy9x+cLM1rdGxUwPaAwB+PpOK0gp1Y5ZJRA1I8gC0efNmhISEYPny5YiJiYGPjw+GDx+OrKyqJxVu3LgRixYtwvLly5GQkIDw8HBs3rwZixcvrvM5iUi/2VsYYfeLj+Do64/i+cGdIJdV3+vzT0M87dHW0gi3isqwl6vLE7UYkgeglStXYvbs2Zg1axa6deuGdevWwcTEBBs2bKhy/xMnTqB///6YMmUK3NzcMGzYMEyePFmnh6e25yQiam9jgraWxrU+zkAuw6Q+lb1AnAxN1HJIGoDKysoQHR2NoKAg7TaZTIagoCBERkZWeUy/fv0QHR2tDTzXrl3D7t27MWrUqDqfs7S0FPn5+TovIqKamtjHBXKZgKjrt3A5s0DqcoioBiQNQDk5OVCr1XBwcNDZ7uDgAJWq6q7kKVOmYMWKFRgwYAAMDQ3RsWNHDB48WDsEVpdzhoWFwdLSUvtycXFpgNYRkb5wtDRCUFd7AOwFImopJB8Cq63Dhw/jvffew+eff46YmBhs374du3btwjvvvFPnc4aGhiIvL0/7Sk3lo+2JqHamBlQ+GXpbzA0Ul1VIXA0RPYyBlB9ua2sLuVyOzMxMne2ZmZlwdHSs8pilS5di2rRpeO655wAAXl5eKCoqwpw5c/Dmm2/W6ZxKpRJKpbIBWkRE+mpAJ1u42pgg+WYxfj+Xgaf6sCeZqDmTtAdIoVDAz88PERER2m0ajQYREREIDAys8pji4mLIZLply+VyAIAoinU6JxFRfclkAqb435sMnSxxNUT0MJIPgYWEhGD9+vX49ttvkZCQgHnz5qGoqAizZs0CAEyfPh2hoaHa/YODg7F27Vps2rQJ169fx/79+7F06VIEBwdrg9DDzklE1Bie8HOGQi7DuRt5OH8jT+pyiOgBJB0CA4CJEyciOzsby5Ytg0qlgq+vL/bu3audxJySkqLT47NkyRIIgoAlS5YgLS0NdnZ2CA4OxrvvvlvjcxIRNQYbMyVGejni19h0/HgqGe87e0tdEhFVQxBFUZS6iOYmPz8flpaWyMvLg4WFhdTlEFELcvqvW3hyXSSMDeU49eZQWBgZSl0Skd6ozfe35ENgREStSW/XNujiYIY75Wr8cjZN6nKIqBoMQEREDUgQBO0t8T+cTAY72YmaJwYgIqIGNq5XOxgbypGUWYgzybelLoeIqsAARETUwCyMDDHG1wkA8ONJ3hJP1BwxABERNYJ7w2C7z6twq6hM4mqI6J8YgIiIGoGXsyW8nS1RptZgyxkur0PU3DAAERE1kqkBlU+G3hiVAo2Gk6GJmhMGICKiRhLs4wRzIwMk3yzG8as5UpdDRP+DAYiIqJGYKAwwoZczACD82HWk595hTxBRM8EnQVeBT4ImooaSlFmAYR8f1f5sZCiDm40p3GxM4W5nCncbU7jZmsLN1gR2ZkoIgiBhtUQtW22+vyVfC4yIqDXr4mCOF4Z0wu9xGUi9VYyScg0uqQpwSVVw375mSgO42Zqgk50ZXhjaGR3tzCSomEg/sAeoCuwBIqLGUK7W4MbtO/grpwjXc4rw183KP6/nFCEt9w7+9//G7ram+OPlgVAYcKYCUU01eg9QamoqBEGAs3Pl2HZUVBQ2btyIbt26Yc6cOXU5JRFRq2col8Hd1hTutqZ49B/vlVaokXqrGNeyi7B4Rzyu5xRhw/HrmDuooyS1ErV2dfrVYsqUKTh06BAAQKVS4V//+heioqLw5ptvYsWKFQ1aIBGRPlAayNHJ3hzDujti0UhPAMBnEZeRmV8icWVErVOdAlB8fDz8/f0BAD///DN69OiBEydO4Mcff8Q333zTkPUREemd8T3boWd7KxSVqfHBnktSl0PUKtUpAJWXl0OpVAIADhw4gMcffxwA4OnpiYyMjIarjohID8lkAt4K7g5BALafTUN08i2pSyJqdeoUgLp3745169bhzz//xP79+zFixAgAQHp6OmxsbBq0QCIifeTjYoWn/FwAAMt3XoCazw8ialB1CkAffPABvvjiCwwePBiTJ0+Gj48PAGDnzp3aoTEiIqqf10Z4wNzIAPFp+dh8muuJETWkOt8Gr1arkZ+fjzZt2mi3/fXXXzAxMYG9vX2DFSgF3gZPRM3FhmPXseL3i2hjYojDrz4KSxNDqUsiarZq8/1dpx6gO3fuoLS0VBt+kpOTsWrVKiQmJrb48ENE1JxMC3RFZ3sz3C4ux8cHkqQuh6jVqFMAGjNmDL777jsAQG5uLgICAvB///d/GDt2LNauXdugBRIR6TNDuQxvPd4dAPD9yWRcUuVLXBFR61CnABQTE4NHHnkEALB161Y4ODggOTkZ3333HT799NMGLZCISN/172SLkT0codaIeGvnBfAB/kT1V6cAVFxcDHNzcwDAvn37MH78eMhkMvTt2xfJyckNWiAREQGLR3WF0kCGk9duYfd5ldTlELV4dQpAnTp1wi+//ILU1FT88ccfGDZsGAAgKyuLk4aJiBqBi7UJ5g2uXBbj3V0XUVxWIXFFRC1bnQLQsmXL8Oqrr8LNzQ3+/v4IDAwEUNkb1LNnzwYtkIiIKs0d1BHtrIyRnleCdYevSl0OUYtW59vgVSoVMjIy4OPjA5msMkdFRUXBwsICnp6eDVpkU+Nt8ETUXO05n4F5P8ZAYSBDRMgguFibSF0SUbPR6LfBA4CjoyN69uyJ9PR03LhxAwDg7+/f4sMPEVFzNqKHI/p1tEFZhQbv/H5R6nKIWqw6BSCNRoMVK1bA0tISrq6ucHV1hZWVFd555x1oNJqGrpGIiO4SBAFvPd4dcpmAfRczcTQpW+qSiFqkOgWgN998E6tXr8b777+Ps2fP4uzZs3jvvffw2WefYenSpQ1dIxER/Y8uDuaYHugKAHj7twsoq+AvnkS1Vac5QE5OTli3bp12Ffh7fv31Vzz//PNIS0trsAKlwDlARNTc5d0px5D/HsbNojIsGd0Vzz3SQeqSiCTX6HOAbt26VeVcH09PT9y6dasupyQiolqwNDbE6yM8AACrDlxGVkGJxBURtSx1CkA+Pj5YvXr1fdtXr14Nb2/vehdFREQP96SfC7ydLVFYWoGV+7hOGFFtGNTloA8//BCjR4/GgQMHtM8AioyMRGpqKnbv3t2gBRIRUdVkMgHLHuuGJ9ZFYvOZVEwLdEV3J0upyyJqEerUAzRo0CAkJSVh3LhxyM3NRW5uLsaPH48LFy7g+++/b+gaiYioGr3drPGYd1uIIrDit4tcJ4yohur8IMSqnDt3Dr169YJarW6oU0qCk6CJqCW5cbsYQ/7vCMoqNFj3tB9G9HCUuiQiSTTJgxAb0po1a+Dm5gYjIyMEBAQgKiqq2n0HDx4MQRDue40ePVq7T2FhIRYsWABnZ2cYGxujW7duWLduXVM0hYioyTm3McGcu3eBvbc7AaUVLfuXUKKmIHkA2rx5M0JCQrB8+XLExMTAx8cHw4cPR1ZWVpX7b9++HRkZGdpXfHw85HI5nnzySe0+ISEh2Lt3L3744QckJCTg5ZdfxoIFC7Bz586mahYRUZOaN7gj7MyVSLlVjG+O/yV1OUTNnuQBaOXKlZg9ezZmzZql7akxMTHBhg0bqtzf2toajo6O2tf+/fthYmKiE4BOnDiBGTNmYPDgwXBzc8OcOXPg4+PzwJ4lIqKWzFRpgNeHV94W/9nBK8guKJW4IqLmrVZ3gY0fP/6B7+fm5tbqw8vKyhAdHY3Q0FDtNplMhqCgIERGRtboHOHh4Zg0aRJMTU212/r164edO3fimWeegZOTEw4fPoykpCR8/PHHVZ6jtLQUpaV//88iPz+/Vu0gImoOJvRyxreRfyE+LR8r9ychbLyX1CURNVu16gGytLR84MvV1RXTp0+v8flycnKgVqvh4OCgs93BwQEqleqhx0dFRSE+Ph7PPfeczvbPPvsM3bp1g7OzMxQKBUaMGIE1a9Zg4MCBVZ4nLCxMpx0uLi41bgMRUXNReVt8dwDA5tMpuJjOX+aIqlOrHqCvv/66seqok/DwcHh5ecHf319n+2effYaTJ09i586dcHV1xdGjRzF//nw4OTkhKCjovvOEhoYiJCRE+3N+fj5DEBG1SP7u1hjt1Ra7zmfgnd8vYuPsAAiCIHVZRM1OnR6E2FBsbW0hl8uRmZmpsz0zMxOOjg++jbOoqAibNm3CihUrdLbfuXMHixcvxo4dO7R3hnl7eyM2Nhb//e9/qwxASqUSSqWynq0hImoeFo30xP6ETEReu4n9FzMxrDtviyf6J0knQSsUCvj5+SEiIkK7TaPRICIiQvuE6eps2bIFpaWlePrpp3W2l5eXo7y8HDKZbtPkcjk0Gq6YTEStn4u1CZ4b4A4AeJe3xRNVSfK7wEJCQrB+/Xp8++23SEhIwLx581BUVIRZs2YBAKZPn64zSfqe8PBwjB07FjY2NjrbLSwsMGjQILz22ms4fPgwrl+/jm+++Qbfffcdxo0b1yRtIiKS2vOPdoKduRLJN4vx3YlkqcshanYkHQIDgIkTJyI7OxvLli2DSqWCr68v9u7dq50YnZKScl9vTmJiIo4dO4Z9+/ZVec5NmzYhNDQUU6dOxa1bt+Dq6op3330Xc+fObfT2EBE1B2ZKA7w23AOvb43DpxGXMb5XO9iYcaif6J4GXQqjteBSGETUGmg0IoJXH8OF9HxMDWiPd8fxtnhq3VrcUhhERNTw7q0WDwA/RaXgkoq3xRPdwwBERNSKBXSwwSgvR2hE4J3fuVo80T0MQERErVzoyK5QyGU4fuUmDiRUvc4ikb5hACIiauVcrE3w7CN3b4vfdRFlFXwkCJHkd4EREVHje35wR2w5cwN/3SzGv78/g65tLWBrpoSNmQJ2ZkrYmClha6aAlYkCchmfHE2tHwMQEZEeMDcyxGvDu+CNbedxKDEbhxKzq9xPJgDWpgptOHKzMcWikZ4wNzJs4oqJGhcDEBGRnniqtwvMlIa4ll2Im0VlyC4sxc3CUuQUluFmYSluF5dDIwI5hWXIKSwDABy/chPGhnIsuXs3GVFrwQBERKQnBEHAaO+21b5frtbgdlHZ3QBUivj0PHy4NxHfRSZjRj83uFibNGG1RI2Lk6CJiAgAYCiXwd7CCN2cLDCwix3mDeqIfh1tUKbWYOX+JKnLI2pQDEBERFQlQRAQOrIrAOCX2DRcSM+TuCKihsMARERE1fJytkSwjxNEEXh/zyWpyyFqMAxARET0QK8N84ChXMCfl3Nw7HKO1OUQNQgGICIieqD2NiaYGuAKAAjbkwCNhstpUMvHAERERA/1wpBOMFMa4EJ6Pn6LS5e6HKJ6YwAiIqKHsjFTYu6gDgCAj/5IRGmFWuKKiOqHAYiIiGrkmQHusDdX4sbtO/jhZIrU5RDVCwMQERHViInCAAv/1QUAsPrgZeSXlEtcEVHdMQAREVGNPennjI52prhdXI51h69KXQ5RnTEAERFRjRnIZXhjhCcAYMPx61DllUhcEVHdMAAREVGt/KubA3q7tkFJuQYf12OJDN5OT1JiACIioloRBAGhoyp7gbZEp+JyZkGtjr+aXYhZX0fBc9leHErMaowSiR6KAYiIiGrNz9Uaw7o5QCMCH+xNrNEx+SXl+M/vFzH846M4lJiNsgoNPjlwuZErJaoaAxAREdXJ6yM8IZcJOJCQidN/3ap2P41GxM+nUzHkv4fx1bHrqNCIGNTFDgq5DLGpuTiXmtt0RRPdxQBERER10sneDE/1dgEAvLc7AaJ4/5ye6OTbGPv5cby+LQ45hWXoYGuKr2f1wbfP+GO0d1sAwHeRyU1aNxHAAERERPWwMKgzjA3lOJuSiz8uqLTbM/NLsHBzLCasPYG4G3kwVxrgzVFdsfflgXjUwx4AMD2wcn2x3+LScauoTJL6SX8xABERUZ3ZWxjhuUfcAQAf7k1EUWkF1hy6gkf/exg7zqZBEICJvV1w8NXBmD2wAxQGf3/t+LpYwaudJcoqNNh8OlWqJpCeYgAiIqJ6mTOwA6xNFbiWU4TAsAh89EciisvU6NXeCr/O748PnvCGnbnyvuMEQdD2Av1wMhlq3hZPTYgBiIiI6sXcyBAvDukEAMgvqYCDhRKrJvpi27x+8Ha2euCxwT5OaGNiiLTcO4hIyGyCaokqGUhdABERtXxTAlyRnlcCM6UBnh3gDlNlzb5ejAzlmNinPdYduYrvIpMxrLtjI1dKVIk9QEREVG8KAxkWj+qKF4d2rnH4uWdqQHsIAnDsSg6uZBU2UoVEuhiAiIhIUi7WJhjq6QCgci4QUVNgACIiIsnN6Fc5GXpr9A0UllZIXA3pAwYgIiKSXP+OtuhgZ4rC0grsiLkhdTmkBxiAiIhIcjKZgOl9K3uBvotMrvKp0kQNqVkEoDVr1sDNzQ1GRkYICAhAVFRUtfsOHjwYgiDc9xo9erTOfgkJCXj88cdhaWkJU1NT9OnTBykpKY3dFCIiqqPxfs4wUchxOasQkdduSl0OtXKSB6DNmzcjJCQEy5cvR0xMDHx8fDB8+HBkZWVVuf/27duRkZGhfcXHx0Mul+PJJ5/U7nP16lUMGDAAnp6eOHz4MOLi4rB06VIYGRk1VbOIiKiWLIwMMb5XOwDAdyc4GZoalyBK3M8YEBCAPn36YPXq1QAAjUYDFxcXvPDCC1i0aNFDj1+1ahWWLVuGjIwMmJqaAgAmTZoEQ0NDfP/993WqKT8/H5aWlsjLy4OFhUWdzkFERLWXlFmAYR8fhUwAjr0xBE5WxlKXRC1Ibb6/Je0BKisrQ3R0NIKCgrTbZDIZgoKCEBkZWaNzhIeHY9KkSdrwo9FosGvXLnTp0gXDhw+Hvb09AgIC8Msvv1R7jtLSUuTn5+u8iIio6XVxMEdgBxtoRGDjKU5boMYjaQDKycmBWq2Gg4ODznYHBweoVKpqjvpbVFQU4uPj8dxzz2m3ZWVlobCwEO+//z5GjBiBffv2Ydy4cRg/fjyOHDlS5XnCwsJgaWmpfbm4uNSvYUREVGf31gf7KSoFpRVqiauh1kryOUD1ER4eDi8vL/j7+2u3aTQaAMCYMWOwcOFC+Pr6YtGiRXjsscewbt26Ks8TGhqKvLw87Ss1lasSExFJ5V/dHNDW0gg3i8qw+3yG1OVQKyVpALK1tYVcLkdmpu4CeJmZmXB0fPB6MEVFRdi0aROeffbZ+85pYGCAbt266Wzv2rVrtXeBKZVKWFhY6LyIiEgaBnIZpga0BwB8y8nQ1EgkDUAKhQJ+fn6IiIjQbtNoNIiIiEBgYOADj92yZQtKS0vx9NNP33fOPn36IDExUWd7UlISXF1dG654IiJqNJP820MhlyE2NRdxN3KlLodaIcmHwEJCQrB+/Xp8++23SEhIwLx581BUVIRZs2YBAKZPn47Q0ND7jgsPD8fYsWNhY2Nz33uvvfYaNm/ejPXr1+PKlStYvXo1fvvtNzz//PON3h4iIqo/WzMlRnu3BVD5YESihla7JXsbwcSJE5GdnY1ly5ZBpVLB19cXe/fu1U6MTklJgUymm9MSExNx7Ngx7Nu3r8pzjhs3DuvWrUNYWBhefPFFeHh4YNu2bRgwYECjt4eIiBrGtEBX7Dibhp3n0rF4VFdYmyqkLolaEcmfA9Qc8TlARETSE0URj68+jvNpeXhjhCfmDe4odUnUzLWY5wARERFVRxAE7S3xP5xMhlrD39ep4TAAERFRsxXs44Q2JoZIy72Dg5eqXiKJqC4YgIiIqNkyMpTjqT6VD6ddd+QqMvNLJK6IWgsGICIiataeDnCFgUxAdPJt9Hv/IOZ8dwaHErM4JEb1wknQVeAkaCKi5uVoUjZWH7yCqL9uabe1szLGpD4ueKqPCxwsjCSsjpqL2nx/MwBVgQGIiKh5upxZgJ+iUrEt5gby7pQDAOQyAUM97TE5oD0GdraDXCZIXCVJhQGonhiAiIiat5JyNfbEZ+CnU6nsFSItBqB6YgAiImo5LmcWYGNUCrbHpOn0Cn0+tReGd3/wupLUuvA5QEREpDc6O5hjeXB3nFo8FB9P9IGPixXUGhFrDl2RujRqxhiAiIioVTAylGNcT2eEz+gNmQDE3chD6q1iqcuiZooBiIiIWhVbMyX6dqhcKHv3+QyJq6HmigGIiIhanVFelSvJ72IAomowABERUaszoocjh8HogRiAiIio1bE1UyLAncNgVD0GICIiapVGeVcOgzEAUVUYgIiIqFUa0b1yGOwch8GoCgxARETUKtmZ/z0MtieevUCkiwGIiIharXvDYLviGIBIFwMQERG1WhwGo+owABERUatlZ66Ev7s1AA6DkS4GICIiatVGax+KqJK4EmpOGICIiKhVG373oYjnUnNx4zaHwagSAxAREbVq9uZGfw+DsReI7mIAIiKiVu/eMNjvfCgi3cUARERErd7wHo4QOAxG/4MBiIiIWj17cyP4u3EYjP7GAERERHrhsXsPReQwGIEBiIiI9MS9YbDY1Fyk5d6RuhySGAMQERHpBd1hMPYC6TsGICIi0hujOQxGdzEAERGR3hhxdxjsbAqHwfQdAxAREekNe3Mj9OEwGIEBiIiI9AzvBiOAAYiIiPTM/w6DpXMYTG8xABERkV7532Gw3ewF0lvNIgCtWbMGbm5uMDIyQkBAAKKioqrdd/DgwRAE4b7X6NGjq9x/7ty5EAQBq1ataqTqiYiopbm3NhgDkP6SPABt3rwZISEhWL58OWJiYuDj44Phw4cjKyuryv23b9+OjIwM7Ss+Ph5yuRxPPvnkffvu2LEDJ0+ehJOTU2M3g4iIWpCRd4fBYjgMprckD0ArV67E7NmzMWvWLHTr1g3r1q2DiYkJNmzYUOX+1tbWcHR01L72798PExOT+wJQWloaXnjhBfz4448wNDR8YA2lpaXIz8/XeRERUetlb2GEPq4cBtNnkgagsrIyREdHIygoSLtNJpMhKCgIkZGRNTpHeHg4Jk2aBFNTU+02jUaDadOm4bXXXkP37t0feo6wsDBYWlpqXy4uLrVvDBERtSj3HorIAKSfJA1AOTk5UKvVcHBw0Nnu4OAAlerhq/VGRUUhPj4ezz33nM72Dz74AAYGBnjxxRdrVEdoaCjy8vK0r9TU1Jo3goiIWiQOg+k3yYfA6iM8PBxeXl7w9/fXbouOjsYnn3yCb775BoIg1Og8SqUSFhYWOi8iImrd/ncYbE/8w3/pptZF0gBka2sLuVyOzMxMne2ZmZlwdHR84LFFRUXYtGkTnn32WZ3tf/75J7KystC+fXsYGBjAwMAAycnJeOWVV+Dm5tbQTSAiohZslFfldw2HwfSPpAFIoVDAz88PERER2m0ajQYREREIDAx84LFbtmxBaWkpnn76aZ3t06ZNQ1xcHGJjY7UvJycnvPbaa/jjjz8apR1ERNQyjfRqC0EAopNvI1FVIHU51IQMpC4gJCQEM2bMQO/eveHv749Vq1ahqKgIs2bNAgBMnz4d7dq1Q1hYmM5x4eHhGDt2LGxsbHS229jY3LfN0NAQjo6O8PDwaNzGEBFRi+JgYYQR3R2xJ16FN7bFYdu8fpDLajZ9glo2yQPQxIkTkZ2djWXLlkGlUsHX1xd79+7VToxOSUmBTKbbUZWYmIhjx45h3759UpRMREStyPLg7jh2OQexqbn4LvIvzOrvLnVJ1AQEURRFqYtobvLz82FpaYm8vDxOiCYi0gM/nkrGmzviYaKQY9/CgXBuYyJ1SVQHtfn+btF3gRERETWEyX3aw9/dGsVlary5Ix7sG2j9GICIiEjvyWQCwsZ7QWEgw5GkbPwamy51SdTIGICIiIgAdLQzw0tDOwMA3v7tAm4WlkpcETUmBiAiIqK75gzsAE9Hc9wuLsc7v1+UuhxqRAxAREREdxnKZfhggjdkAvBLbDoOJWZJXRI1EgYgIiKi/+HjYoVn7t4Kv2RHPApLKySuiBoDAxAREdE/hAzrAuc2xkjLvYP//pEodTnUCBiAiIiI/sFEYYD3xnkBAL6N/AsxKbclrogaGgMQERFRFQZ2scOEXs4QRWDRtjiUVWikLokaEAMQERFRNZaM7gobUwWSMgux9vBVqcuhBsQAREREVI02pgosf7w7AGD1ocu4nMkV41sLBiAiIqIHCPZui6Ge9ihXi3hjWxw0Gi6T0RowABERET2AIAh4Z2wPmCrkiEnJxQ+nkh96TEm5Gqm3ihGTchvnUnMZmpohA6kLICIiau6crIzxxkhPLPv1Aj7YcwnWpgoUllQgu6AUOYWlyC4sRU5B2d0/S1Hwj2cHtbMyxvhe7TCuZzt0sDOTqBX0vwSRS97eJz8/H5aWlsjLy4OFhYXU5RARUTOg0Yh48otIRCfX7JZ4hYEMdmZK5N8p1wlEvdpbYXwvZwR7O8HSxLCxytVLtfn+ZgCqAgMQERFV5Vp2IRZujoVGBOzMlbA1U9z9U3nfnxZGBhAEASXlauy/mIltMTdwNCkb90bDFHIZgrrZY3xPZwzysIOhnLNS6osBqJ4YgIiIqDFkFZRgZ2w6tkbfwCXV33eU2Zgq8LivEyb0ckZ3JwsIgiBhlS0XA1A9MQAREVFju5iej20xN/BrbBpyCsu02//VzQGrp/SE0kAuYXUtEwNQPTEAERFRU6lQa3D0cja2xaRh/4VMlKk1GOppj7VP+0FhwGGx2qjN9zf/yRIREUnIQC7DEE8HrJnSC9/M6gOlgQwRl7Iwf2MMytVcfqOxMAARERE1E/062eKrGb2hMJBh/8VMvPjTWYagRsIARERE1Iw80tkOX0zzg0Iuw554FRZujkUFQ1CDYwAiIiJqZh71sMfap3vBUC7g97gMvLLlHNR8mnSDYgAiIiJqhoZ2dcDqKb1gIBPwa2w6XtvKENSQGICIiIiaqeHdHfHZ5J6QywRsj0lD6HYuxtpQGICIiIiasZFebbFqoi9kAvDzmRt485d4hqAGwABERETUzAX7OGHlU74QBOCnqBQs33kBfIxf/TAAERERtQBje7bDR0/4QBCA708m4+3fLjIE1YOB1AUQERFRzTzh5wyNRsTr2+LwzYm/IJcJeHFIZ64qXwdcCqMKXAqDiIias42nUrB4x3ntz44WRvBwNIenozk87r462Zvp3Xpitfn+Zg8QERFRCzMloD0M5AI+OXAZabl3oMovgSq/BEeSsrX7yGUC3G1NK4ORQ2Uo6uXaBrZmSgkrbz7YA1QF9gAREVFLkV9SjiRVAS6pCpB493VJlY/8kor79pXLBDzqYYcJvZwxpKt9q+sh4mrw9cQARERELZkoilDll2hDUZKqABfS85GYWaDdx8rEEGN8nDDBzxle7SwhCIKEFTcMBqB6YgAiIqLW6EpWIbbF3MD2mBvIzC/Vbu/iYIYJvZwxrmc72FsYSVhh/dTm+7tZ3Aa/Zs0auLm5wcjICAEBAYiKiqp238GDB0MQhPteo0ePBgCUl5fjjTfegJeXF0xNTeHk5ITp06cjPT29qZpDRETULHWyN8MbIzxxYtFQfPeMPx73cYLSQIakzEKE7bmEvmERmPV1FHbFZaCkXC11uY1K8h6gzZs3Y/r06Vi3bh0CAgKwatUqbNmyBYmJibC3t79v/1u3bqGsrEz7882bN+Hj44OvvvoKM2fORF5eHp544gnMnj0bPj4+uH37Nl566SWo1WqcOXOmRjWxB4iIiPRFfkk5dsVlYGv0DUQn39ZutzAywPhezpjk7wJPx5bxXdiihsACAgLQp08frF69GgCg0Wjg4uKCF154AYsWLXro8atWrcKyZcuQkZEBU1PTKvc5ffo0/P39kZycjPbt2z/0nAxARESkj65lF2J7TBq2x9xAel6JdnvP9laY7N8ej3m3hYmi+d5A3mJugy8rK0N0dDRCQ0O122QyGYKCghAZGVmjc4SHh2PSpEnVhh8AyMvLgyAIsLKyqvL90tJSlJb+PRaan59fswYQERG1Ih3szPDqcA+E/KsLjl3JwabTKdh3IRNnU3JxNiUX7/x2EWN7tsNk//bo5tSyOwgkDUA5OTlQq9VwcHDQ2e7g4IBLly499PioqCjEx8cjPDy82n1KSkrwxhtvYPLkydWmwbCwMLz99tu1K56IiKiVkskEDOxih4Fd7JBdUIqt0Tew6XQKkm8W4/uTyfj+ZDJ8XKwwuY8Lgn2cYKpsvr1C1WkWk6DrKjw8HF5eXvD396/y/fLycjz11FMQRRFr166t9jyhoaHIy8vTvlJTUxurZCIiohbFzlyJeYM74tArg7HxuQA85t0WhnIB51JzsWj7efi/ewCLd5xH0v/cYt8SSBrZbG1tIZfLkZmZqbM9MzMTjo6ODzy2qKgImzZtwooVK6p8/174SU5OxsGDBx84FqhUKqFU8smYRERE1ZHJBPTrZIt+nWxxs7AU22JuYFNUKq7lFGHjqRRsPXMD3z3rj74dbKQutUYk7QFSKBTw8/NDRESEdptGo0FERAQCAwMfeOyWLVtQWlqKp59++r737oWfy5cv48CBA7CxaRkXg4iIqCWwMVNizsCOiHhlEDbN6Yt+HW1QptZgzndncLmF9ARJPgQWEhKC9evX49tvv0VCQgLmzZuHoqIizJo1CwAwffp0nUnS94SHh2Ps2LH3hZvy8nI88cQTOHPmDH788Ueo1WqoVCqoVCqd2+eJiIiofgRBQN8ONtgwsw/8XNsgv6QCM78+jaz8kocfLDHJZy1NnDgR2dnZWLZsGVQqFXx9fbF3717txOiUlBTIZLo5LTExEceOHcO+ffvuO19aWhp27twJAPD19dV579ChQxg8eHCjtIOIiEhfGRnK8dX03piw9gSu5RRh1jen8fO/A5v15GjJnwPUHPE5QERERLWXcrMY4z4/jptFZRjsYYevpveGgbzpBpta3FIYRERE1PK1tzFB+Mw+MDKU4XBiNpb8Eo/m2s/CAEREREQNxtfFCp9N7gWZAGw6nYo1h65IXVKVGICIiIioQf2rmwPefrw7AOC/+5KwPeaGxBXdjwGIiIiIGty0QDf8e1AHAMDrW+Nw/EqOxBXpYgAiIiKiRvHGcE8E+zihQiNi7vfRuKRqPmttMgARERFRo5DJBPz3SW/4u1ujoLQCs74+DVVe83hGEAMQERERNRqlgRzrp/VGJ3szZOSVYObXUSgoKZe6LAYgIiIialyWJob4emYf2JkrcUlVgOd/jEG5WiNpTQxARERE1OhcrE2wYUYfmCjk+PNyDkK3n5f0GUEMQERERNQkvJwtsWZKL8hlAuzNlZDyGYnNd5EOIiIianUe9bTHHy8PRCd7M0nrYA8QERERNSmpww/AAERERER6iAGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcMpC6gORJFEQCQn58vcSVERERUU/e+t+99jz8IA1AVCgoKAAAuLi4SV0JERES1VVBQAEtLywfuI4g1iUl6RqPRID09Hebm5hAEoUHPnZ+fDxcXF6SmpsLCwqJBz92c6EM79aGNANvZ2rCdrYc+tBGoXTtFUURBQQGcnJwgkz14lg97gKogk8ng7OzcqJ9hYWHRqv+FvUcf2qkPbQTYztaG7Ww99KGNQM3b+bCen3s4CZqIiIj0DgMQERER6R0GoCamVCqxfPlyKJVKqUtpVPrQTn1oI8B2tjZsZ+uhD20EGq+dnARNREREeoc9QERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwDUhNasWQM3NzcYGRkhICAAUVFRUpfUoN566y0IgqDz8vT0lLqsejt69CiCg4Ph5OQEQRDwyy+/6LwviiKWLVuGtm3bwtjYGEFBQbh8+bI0xdbDw9o5c+bM+67viBEjpCm2jsLCwtCnTx+Ym5vD3t4eY8eORWJios4+JSUlmD9/PmxsbGBmZoYJEyYgMzNToorrpibtHDx48H3Xc+7cuRJVXDdr166Ft7e39gF5gYGB2LNnj/b91nAtgYe3szVcy396//33IQgCXn75Ze22hr6eDEBNZPPmzQgJCcHy5csRExMDHx8fDB8+HFlZWVKX1qC6d++OjIwM7evYsWNSl1RvRUVF8PHxwZo1a6p8/8MPP8Snn36KdevW4dSpUzA1NcXw4cNRUlLSxJXWz8PaCQAjRozQub4//fRTE1ZYf0eOHMH8+fNx8uRJ7N+/H+Xl5Rg2bBiKioq0+yxcuBC//fYbtmzZgiNHjiA9PR3jx4+XsOraq0k7AWD27Nk61/PDDz+UqOK6cXZ2xvvvv4/o6GicOXMGQ4YMwZgxY3DhwgUAreNaAg9vJ9Dyr+X/On36NL744gt4e3vrbG/w6ylSk/D39xfnz5+v/VmtVotOTk5iWFiYhFU1rOXLl4s+Pj5Sl9GoAIg7duzQ/qzRaERHR0fxo48+0m7Lzc0VlUql+NNPP0lQYcP4ZztFURRnzJghjhkzRpJ6GktWVpYIQDxy5IgoipXXztDQUNyyZYt2n4SEBBGAGBkZKVWZ9fbPdoqiKA4aNEh86aWXpCuqkbRp00b86quvWu21vOdeO0WxdV3LgoICsXPnzuL+/ft12tUY15M9QE2grKwM0dHRCAoK0m6TyWQICgpCZGSkhJU1vMuXL8PJyQkdOnTA1KlTkZKSInVJjer69etQqVQ619bS0hIBAQGt7toCwOHDh2Fvbw8PDw/MmzcPN2/elLqkesnLywMAWFtbAwCio6NRXl6ucz09PT3Rvn37Fn09/9nOe3788UfY2tqiR48eCA0NRXFxsRTlNQi1Wo1NmzahqKgIgYGBrfZa/rOd97SWazl//nyMHj1a57oBjfPfJhdDbQI5OTlQq9VwcHDQ2e7g4IBLly5JVFXDCwgIwDfffAMPDw9kZGTg7bffxiOPPIL4+HiYm5tLXV6jUKlUAFDltb33XmsxYsQIjB8/Hu7u7rh69SoWL16MkSNHIjIyEnK5XOryak2j0eDll19G//790aNHDwCV11OhUMDKykpn35Z8PatqJwBMmTIFrq6ucHJyQlxcHN544w0kJiZi+/btElZbe+fPn0dgYCBKSkpgZmaGHTt2oFu3boiNjW1V17K6dgKt51pu2rQJMTExOH369H3vNcZ/mwxA1GBGjhyp/bu3tzcCAgLg6uqKn3/+Gc8++6yElVFDmDRpkvbvXl5e8Pb2RseOHXH48GEMHTpUwsrqZv78+YiPj28V89QepLp2zpkzR/t3Ly8vtG3bFkOHDsXVq1fRsWPHpi6zzjw8PBAbG4u8vDxs3boVM2bMwJEjR6Quq8FV185u3bq1imuZmpqKl156Cfv374eRkVGTfCaHwJqAra0t5HL5fbPVMzMz4ejoKFFVjc/KygpdunTBlStXpC6l0dy7fvp2bQGgQ4cOsLW1bZHXd8GCBfj9999x6NAhODs7a7c7OjqirKwMubm5Ovu31OtZXTurEhAQAAAt7noqFAp06tQJfn5+CAsLg4+PDz755JNWdy2ra2dVWuK1jI6ORlZWFnr16gUDAwMYGBjgyJEj+PTTT2FgYAAHB4cGv54MQE1AoVDAz88PERER2m0ajQYRERE6Y7itTWFhIa5evYq2bdtKXUqjcXd3h6Ojo861zc/Px6lTp1r1tQWAGzdu4ObNmy3q+oqiiAULFmDHjh04ePAg3N3ddd738/ODoaGhzvVMTExESkpKi7qeD2tnVWJjYwGgRV3Pqmg0GpSWlraaa1mde+2sSku8lkOHDsX58+cRGxurffXu3RtTp07V/r3Br2f952xTTWzatElUKpXiN998I168eFGcM2eOaGVlJapUKqlLazCvvPKKePjwYfH69evi8ePHxaCgINHW1lbMysqSurR6KSgoEM+ePSuePXtWBCCuXLlSPHv2rJicnCyKoii+//77opWVlfjrr7+KcXFx4pgxY0R3d3fxzp07EldeOw9qZ0FBgfjqq6+KkZGR4vXr18UDBw6IvXr1Ejt37iyWlJRIXXqNzZs3T7S0tBQPHz4sZmRkaF/FxcXafebOnSu2b99ePHjwoHjmzBkxMDBQDAwMlLDq2ntYO69cuSKuWLFCPHPmjHj9+nXx119/FTt06CAOHDhQ4sprZ9GiReKRI0fE69evi3FxceKiRYtEQRDEffv2iaLYOq6lKD64na3lWlbln3e3NfT1ZABqQp999pnYvn17UaFQiP7+/uLJkyelLqlBTZw4UWzbtq2oUCjEdu3aiRMnThSvXLkidVn1dujQIRHAfa8ZM2aIolh5K/zSpUtFBwcHUalUikOHDhUTExOlLboOHtTO4uJicdiwYaKdnZ1oaGgourq6irNnz25xAb6q9gEQv/76a+0+d+7cEZ9//nmxTZs2oomJiThu3DgxIyNDuqLr4GHtTElJEQcOHChaW1uLSqVS7NSpk/jaa6+JeXl50hZeS88884zo6uoqKhQK0c7OThw6dKg2/Ihi67iWovjgdraWa1mVfwaghr6egiiKYt36joiIiIhaJs4BIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiKqAUEQ8Msvv0hdBhE1EAYgImr2Zs6cCUEQ7nuNGDFC6tKIqIUykLoAIqKaGDFiBL7++mudbUqlUqJqiKilYw8QEbUISqUSjo6OOq82bdoAqByeWrt2LUaOHAljY2N06NABW7du1Tn+/PnzGDJkCIyNjWFjY4M5c+agsLBQZ58NGzage/fuUCqVaNu2LRYsWKDzfk5ODsaNGwcTExN07twZO3fubNxGE1GjYQAiolZh6dKlmDBhAs6dO4epU6di0qRJSEhIAAAUFRVh+PDhaNOmDU6fPo0tW7bgwIEDOgFn7dq1mD9/PubMmYPz589j586d6NSpk85nvP3223jqqacQFxeHUaNGYerUqbh161aTtpOIGki916snImpkM2bMEOVyuWhqaqrzevfdd0VRFEUA4ty5c3WOCQgIEOfNmyeKoih++eWXYps2bcTCwkLt+7t27RJlMpmoUqlEURRFJycn8c0336y2BgDikiVLtD8XFhaKAMQ9e/Y0WDuJqOlwDhARtQiPPvoo1q5dq7PN2tpa+/fAwECd9wIDAxEbGwsASEhIgI+PD0xNTbXv9+/fHxqNBomJiRAEAenp6Rg6dOgDa/D29tb+3dTUFBYWFsjKyqprk4hIQgxARNQimJqa3jck1VCMjY1rtJ+hoaHOz4IgQKPRNEZJRNTIOAeIiFqFkydP3vdz165dAQBdu3bFuXPnUFRUpH3/+PHjkMlk8PDwgLm5Odzc3BAREdGkNRORdNgDREQtQmlpKVQqlc42AwMD2NraAgC2bNmC3r17Y8CAAfjxxx8RFRWF8PBwAMDUqVOxfPlyzJgxA2+99Rays7PxwgsvYNq0aXBwcAAAvPXWW5g7dy7s7e0xcuRIFBQU4Pjx43jhhReatqFE1CQYgIioRdi7dy/atm2rs83DwwOXLl0CUHmH1qZNm/D888+jbdu2+Omnn9CtWzcAgImJCf744w+89NJL6NOnD0xMTDBhwgSsXLlSe64ZM2agpKQEH3/8MV599VXY2triiSeeaLoGElGTEkRRFKUugoioPgRBwI4dOzB27FipSyGiFoJzgIiIiEjvMAARERGR3uEcICJq8TiST0S1xR4gIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpnf8HTTWIHaW2zVcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=0.05),\n",
    "            A.HorizontalFlip(p=0.07),\n",
    "            A.VerticalFlip(p=0.08),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0],\n",
    "                std=[1.0, 1.0, 1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "\n",
    "    )\n",
    "    val_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT,width=IMAGE_WIDTH),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    model = load_model('UNet').to(device= DEVICE)\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters() ,weight_decay=0.02)\n",
    "    warmup = LRWarmup(epochs=NUM_EPOCHS, max_lr=LEARNING_RATE, k=0.77)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, warmup.lr_warmup)\n",
    "    train_loader , val_loader = get_loaders(\n",
    "        TRAIN_IMG_DIR,\n",
    "        TRAIN_MASK_DIR,\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_MASK_DIR,\n",
    "        BATCH_SIZE,\n",
    "        train_transform,\n",
    "        val_transform,\n",
    "        NUM_WORKERS,\n",
    "        PIN_MEMORY\n",
    "    )\n",
    "    # print(\"olaaaaaaaaaaaaa\")\n",
    "\n",
    "    if LOAD_MODEL == 1:\n",
    "        load_checkpoint(torch.load(hyp1), model)\n",
    "    elif LOAD_MODEL == 2 :\n",
    "        load_checkpoint(torch.load(hyp2), model)\n",
    "        \n",
    "    check_accuracy(val_loader,model,loss_fn,device=DEVICE)\n",
    "    losses = []\n",
    "\n",
    "    for epochs in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "        losses.append(loss)\n",
    "        checkpoint = {\n",
    "            \"state_dict\":model.state_dict(),\n",
    "            \"optimizer\":optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "        check_accuracy(val_loader,model,loss_fn,device = DEVICE)\n",
    "\n",
    "        save_predictions_as_imgs(\n",
    "            val_loader,model,folder = \"saved_images/\" ,device = DEVICE\n",
    "\n",
    "        )\n",
    "        lr_scheduler.step()\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"my_checkpoint_scheduler.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn):\n",
    "\n",
    "    loop = tqdm.tqdm(loader)\n",
    "    losses = []\n",
    "\n",
    "    for (data,targets) in (loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        print(\"ollllllllllllAA\",data.shape)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "        # print(targets.shape)\n",
    "        predictions = model(data)\n",
    "\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return sum(losses) / len(losses)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "model = load_model('UNet').to(device= DEVICE)\n",
    "load_checkpoint(torch.load(pth),model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (ups): ModuleList(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downs): ModuleList(\n",
       "    (0): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DoubleConv(\n",
       "      (relusig): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReluSIG(\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (bottleneck): DoubleConv(\n",
       "    (relusig): ReluSIG(\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReluSIG(\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (add_skip): ListSkip(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv1d): Conv2d(64, 256, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n",
       "    (conv1dd): Conv2d(64, 512, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1))\n",
       "    (conv2d): Conv2d(128, 512, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT,width=IMAGE_WIDTH),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),  # Resize the image to match the model input size if necessary\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "  \n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  \n",
    "    return image\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"im/000142.png\"\n",
    "image = preprocess_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 160, 160])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C:/Users/haZAR/Desktop/Subahnshu_Sethi_ResearchTeam/Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,image):\n",
    "    image = preprocess_image(image)\n",
    "    with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(image))\n",
    "            preds = (preds > 0.5).float()\n",
    "    torchvision.utils.save_image(\n",
    "          preds, f\"{\"C:/Users/haZAR/Desktop/Subahnshu_Sethi_ResearchTeam/Segmentation\"}/pred.png\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, image)\u001b[0m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m preprocess_image(image)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 4\u001b[0m         preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m         preds \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      6\u001b[0m torchvision\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39msave_image(\n\u001b[0;32m      7\u001b[0m       preds, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/haZAR/Desktop/Subahnshu_Sethi_ResearchTeam/Segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pred.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m       )\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8368\\276278340.py:56\u001b[0m, in \u001b[0;36mUNET.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m skip_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,down \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdowns):\n\u001b[1;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     skip_connections\u001b[38;5;241m.\u001b[39mappend(x) \u001b[38;5;66;03m##adding of previsous layer slip connections\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8368\\276278340.py:23\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "predict(model,img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),  # Resize the image to match the model input size if necessary\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')  # Convert image to grayscale\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension\n",
    "    return image.float()\n",
    "\n",
    "# Predict function\n",
    "def predict(model, image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    \n",
    "    # Remove batch dimension and channel dimension\n",
    "    preds = preds.squeeze(0).squeeze(0)\n",
    "\n",
    "    print(f'Prediction shape: {preds.shape}')\n",
    "    print(f'Prediction min value: {preds.min()}')\n",
    "    print(f'Prediction max value: {preds.max()}')\n",
    "\n",
    "    # Display the original image and the segmentation mask\n",
    "    original_image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_image, cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(preds, cmap='gray', vmin=0, vmax=1)  # Normalize between 0 and 1\n",
    "    plt.title('Segmentation Mask')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage (assuming you have a model defined):\n",
    "# model = ...  # Your model here\n",
    "# predict(model, 'path_to_image.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 23\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, image_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m image \u001b[38;5;241m=\u001b[39m preprocess_image(image_path)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 23\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Remove batch dimension and channel dimension\u001b[39;00m\n\u001b[0;32m     26\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8368\\276278340.py:56\u001b[0m, in \u001b[0;36mUNET.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m skip_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,down \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdowns):\n\u001b[1;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     skip_connections\u001b[38;5;241m.\u001b[39mappend(x) \u001b[38;5;66;03m##adding of previsous layer slip connections\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8368\\276278340.py:23\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "predict(model,img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define the transformation to preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),  # Resize the image to match the model input size if necessary\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')  # Convert image to grayscale\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension\n",
    "    return image.float()\n",
    "\n",
    "def predict_and_plot(model, image_path, device='cuda'):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path)\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(model(image))\n",
    "        preds = preds.squeeze(0).cpu()  # Remove batch dimension and move to CPU\n",
    "\n",
    "    # Plot the original image and the predicted heatmap\n",
    "    original_image = Image.open(image_path).convert('L')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(original_image, cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    \n",
    "    ax[1].imshow(original_image, cmap='gray')\n",
    "    ax[1].imshow(preds[0], cmap='hot', alpha=0.5)  # Overlay predicted heatmap\n",
    "    ax[1].set_title('Predicted Heatmap Overlay')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# model = ...  # Your trained model\n",
    "# image_path = 'path_to_your_image.png'\n",
    "# predict_and_plot(model, image_path, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(model(image))\n",
    "    preds = preds.squeeze(0)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(preds)\n",
    "    plt.title('Predicted Heatmap Overlay')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict(model,\u001b[43mimg\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "predict(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
